{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download MNIST Dataset using sklearn\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST ORIGINAL')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is an array with one row per instance and one per feature (70000 samples, pictures of 28x28)\n",
    "# target is an array containing all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size:(70000, 784)\n",
      "y size:(70000,)\n"
     ]
    }
   ],
   "source": [
    "# verify data size:\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(\"X size:\" + str(X.shape)+\"\\n\" + \"y size:\" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2af03760a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE SOME DATA FROM MNIST DATASET:\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 55000     # Change this value to show a different number \n",
    "some_digit = X[index]\n",
    "some_digit_image = some_digit.reshape(28,28) \n",
    "\n",
    "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of its corresponding label: 9.0\n"
     ]
    }
   ],
   "source": [
    "# verify if their label value corresponds with the image shown above\n",
    "print(\"Value of its corresponding label: \" +str(y[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A TRAINING SET AND TEST SET:\n",
    "X_train, y_train, X_test, y_test = X[:60000], y[:60000], X[60000:], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE THE DATA:\n",
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lit_a\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BINARY CLASSIFIER\n",
    "# this is an simple example of how to implement a binary classifier using a Stocastich Gradient Descent(SDG)\n",
    "\n",
    "# create a new training and testing labels:\n",
    "y_train_5 = (y_train == 5) # true for all 5s \n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# import SDG from sklearn library and train it\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train,y_train_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the Classifier works:\n",
    "# if the value of some digit corresponds to 5, the following code will return a True value\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lit_a\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\users\\lit_a\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\users\\lit_a\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96235, 0.8969 , 0.76805])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PERFORMANCE MEASURES:\n",
    "# Using K-fold Cross-validation:\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")  # this will evaluate the trainig data using three folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but remember: accuracy is not the best parameter to measure performance on classification problems (specially with skewed datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lit_a\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\users\\lit_a\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\users\\lit_a\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "# Let's try using a confusion matrix to determine if our model is accurate enough\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47805,  6774],\n",
       "       [  680,  4741]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using predictions to build the confusion matrix:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 47805 non-fives true negatives, 6774 non-fives false positives\n",
    "# 680   fives false positives, 4741 fives true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41172383847155886\n",
      "\n",
      "0.8745618889503781\n"
     ]
    }
   ],
   "source": [
    "# PRECISION AND RECALL\n",
    "# Precision and recall gives you a better understanding of the confusion matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(str(precision_score(y_train_5, y_train_pred))+\"\\n\")\n",
    "print(recall_score(y_train_5,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5598724610297591"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using F1 metrics:\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
